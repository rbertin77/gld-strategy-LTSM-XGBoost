{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46301bdc-e7aa-4a96-8f00-63b1da8670c8",
   "metadata": {},
   "source": [
    "# Walk-Forward Validation Runner and Analysis\n",
    "\n",
    "This notebook executes a full Walk-Forward Validation pipeline and analyzes the aggregated out-of-sample results. This provides a more robust estimate of the strategy's performance across different market regimes, serving as the ultimate test of its viability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0169950-1914-41bf-84c0-0eceb9a2e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the project's root directory\n",
    "# os.getcwd() gets the current folder ('/notebooks')\n",
    "# os.path.join(..., '..') goes one level up to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add the project root to the Python path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# --- Imports and Setup ---\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Import custom project modules\n",
    "from src.training_pipeline import TrainingPipeline\n",
    "from src.backtester import VectorizedBacktester\n",
    "from src.utils import plot_confusion_matrix, plot_roc_curve\n",
    "\n",
    "# --- Load Configuration ---\n",
    "# Construct the absolute path to the config file using project_root\n",
    "config_path = os.path.join(project_root, 'configs', 'config.yaml')\n",
    "print(f\"Loading configuration from: {config_path}\")\n",
    "with open(config_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "print(\"Configuration loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a460efc-4a7e-414c-aa71-fcff228302a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the training pipeline, passing the project_root\n",
    "pipeline = TrainingPipeline(config=config, project_root=project_root)\n",
    "\n",
    "# Run the entire walk-forward validation process.\n",
    "# WARNING: This will take a significant amount of time to run,\n",
    "# as it trains and evaluates the model 5 times.\n",
    "wf_results = pipeline.run_walk_forward(n_splits=5)\n",
    "\n",
    "print(\"\\n\\n✅ --- Walk-Forward Validation Finished! --- ✅\")\n",
    "print(\"Aggregated results are now available in the 'wf_results' variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692b590-6206-4a0f-b900-efabc6e1a879",
   "metadata": {},
   "source": [
    "## 1. Aggregated Statistical Performance Analysis\n",
    "\n",
    "Here we analyze the combined performance across all out-of-sample folds. This gives us a single, robust view of the model's predictive power over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc60082-e222-426d-84e0-70ad876bd5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Analyzing aggregated out-of-sample results...\")\n",
    "\n",
    "# Extract the combined results from all folds\n",
    "true_labels = wf_results['true_labels']\n",
    "pred_probas = wf_results['pred_probas']\n",
    "binary_preds = (pred_probas > 0.5).astype(int)\n",
    "\n",
    "# --- Display Overall Metrics ---\n",
    "print(\"\\n--- Overall Classification Report (All Out-of-Sample Folds) ---\")\n",
    "print(classification_report(true_labels, binary_preds))\n",
    "\n",
    "# --- Plot Overall Evaluation Graphs ---\n",
    "plot_confusion_matrix(true_labels, binary_preds)\n",
    "plot_roc_curve(true_labels, pred_probas, \"Walk-Forward Aggregated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b91695-c1c5-4dc1-b0bf-423a727b987c",
   "metadata": {},
   "source": [
    "## 2. Aggregated Backtest Performance\n",
    "\n",
    "This is the final and most important test. We combine the out-of-sample signals from all folds into a single continuous timeline and run one final backtest. This simulates how the strategy would have performed in a real-world scenario where the model is periodically retrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cf3266-33a4-4b64-95b0-0d78ff090c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the combined backtest dataframe from the results\n",
    "backtest_df = wf_results['backtest_df']\n",
    "\n",
    "print(f\"Aggregated backtest will run on {len(backtest_df)} signals.\")\n",
    "print(f\"Covering the period from {backtest_df.index.min().date()} to {backtest_df.index.max().date()}.\")\n",
    "\n",
    "# Instantiate and run the backtester on the combined out-of-sample signals\n",
    "backtester = VectorizedBacktester(\n",
    "    price_data=backtest_df,\n",
    "    signals=backtest_df['signal'],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Run the backtest with exit signals enabled\n",
    "portfolio = backtester.run(commission=0.001, slippage=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05421b71-04af-4d4b-8736-7b35ab0b61ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
